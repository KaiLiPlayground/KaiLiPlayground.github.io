<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="AWS ETL + Airflow project">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Kai Li">
    
    <title>
        
            MovieLens - Project 2 |
        
        Kai Li
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/hello_new.jpg">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"kailiplayground.github.io","root":"/","language":"en","path":"search.xml"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066cc","logo":"/images/hello_new.jpg","favicon":"/images/hello_new.jpg","avatar":"/images/hello_new.jpg","font_size":null,"font_family":null,"hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving.","font_color":null,"hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":true,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"enable":false,"wordcount":false,"min2read":false},"img_align":"left","copyright_info":false},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/hello_new.jpg">
                </a>
            
            <a class="logo-title" href="/">
               Kai Li
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">MovieLens - Project 2</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/hello_new.jpg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Kai Li</span>
                            
                                <span class="author-label">Lv1</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2024-01-31 16:27:22</span>
        <span class="mobile">2024-01-31 16:27</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2024-02-01 10:10:40</span>
    </span>
    
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/AWS/">AWS</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/AWS-Lambda/">AWS Lambda</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/AWS-EMR/">AWS EMR</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/AWS-Airflow/">AWS Airflow</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <h1 id="Building-an-Automated-Data-Pipeline-with-AWS-Airflow-and-Redshift"><a href="#Building-an-Automated-Data-Pipeline-with-AWS-Airflow-and-Redshift" class="headerlink" title="Building an Automated Data Pipeline with AWS, Airflow, and Redshift"></a>Building an Automated Data Pipeline with AWS, Airflow, and Redshift</h1><p>In this post, Iâ€™ll walk you through setting up an automated data pipeline using AWS CloudFormation, Apache Airflow, Amazon EMR, and Amazon Redshift. This pipeline converts CSV files to Parquet format and then loads them into a Redshift data warehouse for further data modeling and scalability. </p>
<p>We went above and beyond the original <a class="link"   target="_blank" rel="noopener" href="https://aws.amazon.com/blogs/big-data/build-a-concurrent-data-orchestration-pipeline-using-amazon-emr-and-apache-livy/" >blog post<i class="fas fa-external-link-alt"></i></a> where the author has outdated scripts and configuration errors and plust the services in cloudformation setup are not up to date. In addition, we have also added data catalog to allow Athena query along with the idea of sending the parquet data to redshift. </p>
<h2 id="1-AWS-CloudFormation-Template-for-Infrastructure-Setup"><a href="#1-AWS-CloudFormation-Template-for-Infrastructure-Setup" class="headerlink" title="1. AWS CloudFormation Template for Infrastructure Setup"></a>1. AWS CloudFormation Template for Infrastructure Setup</h2><p>We start by defining the necessary infrastructure using an AWS CloudFormation template. This includes setting up an EC2 instance, Postgres RDS for the Airflow metastore, S3 bucket, and the necessary roles.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">AWSTemplateFormatVersion:</span> <span class="string">&#x27;2010-09-09&#x27;</span></span><br><span class="line"><span class="attr">Description:</span> <span class="string">Airflow</span> <span class="string">server</span> <span class="string">backed</span> <span class="string">by</span> <span class="string">Postgres</span> <span class="string">RDS</span> <span class="string">with</span> <span class="string">VPC</span> <span class="string">and</span> <span class="string">subnets</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Parameters:</span></span><br><span class="line">  <span class="string">...</span> [<span class="string">parameters</span> <span class="string">here</span>] <span class="string">...</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Mappings:</span></span><br><span class="line">  <span class="string">...</span> [<span class="string">AMI</span> <span class="string">mappings</span> <span class="string">here</span>] <span class="string">...</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Resources:</span></span><br><span class="line">  <span class="string">...</span> [<span class="string">resource</span> <span class="string">definitions</span> <span class="string">here</span>] <span class="string">...</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Outputs:</span></span><br><span class="line">  <span class="string">...</span> [<span class="string">outputs</span> <span class="string">here</span>] <span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>The full cloudformation template can be accessed at <a class="link"   target="_blank" rel="noopener" href="https://github.com/KaiLiPlayground/MovieLens_ETL_Proj/blob/main/movie_etl_proj/airflow/cloudformation/airflow.yaml" >airflow3.yml<i class="fas fa-external-link-alt"></i></a>.</p>
<p>Here is how it looks like when all resources are deployed successfully</p>
<p><img src="/2024/01/31/MovieLensProj/airflow3_c_stack.png"></p>
<h2 id="Airflow-service-setup"><a href="#Airflow-service-setup" class="headerlink" title="Airflow service setup"></a>Airflow service setup</h2><p>The following commands included for service installation, Airflow scheduler start up and Airflow webserver start up, Airflow admin user creation, and Airflow services shut down for services restart. </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line"></span><br><span class="line">mkdir -p ~/p2/airflow</span><br><span class="line"></span><br><span class="line">python3 -m venv ~/p2/airflow/venv</span><br><span class="line">source ~/p2/airflow/venv/bin/activate</span><br><span class="line"></span><br><span class="line">AIRFLOW_VERSION=2.8.1</span><br><span class="line">PYTHON_VERSION=&quot;$(python3 --version | cut -d &quot; &quot; -f 2 | cut -d &quot;.&quot; -f 1-2)&quot;</span><br><span class="line">CONSTRAINT_URL=&quot;https://raw.githubusercontent.com/apache/airflow/constraints-$&#123;AIRFLOW_VERSION&#125;/constraints-$&#123;PYTHON_VERSION&#125;.txt&quot;</span><br><span class="line">pip install &quot;apache-airflow[crypto,postgres]==$&#123;AIRFLOW_VERSION&#125;&quot; --constraint &quot;$&#123;CONSTRAINT_URL&#125;&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Additional dependencies <span class="keyword">if</span> needed</span></span><br><span class="line">sudo pip install six --upgrade</span><br><span class="line">sudo pip install markupsafe --upgrade</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set up environment variables</span></span><br><span class="line">echo &#x27;export PATH=/usr/local/bin:$PATH&#x27; &gt;&gt; /root/.bash_profile</span><br><span class="line">source /root/.bash_profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Initialize Airflow</span></span><br><span class="line">airflow initdb</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Configure Airflow settings</span></span><br><span class="line">sed -i &#x27;/sql_alchemy_conn/s/^/#/g&#x27; ~/airflow/airflow.cfg</span><br><span class="line">sed -i &#x27;/sql_alchemy_conn/c\sql_alchemy_conn = postgresql://airflow:airflowpassword@airflowstack2024-dbinstance-vc9uopllco1y.cgppbdvzhe7r.ap-southeast-2.rds.amazonaws.com:5432/airflowdb</span><br><span class="line">sed -i &#x27;/executor = SequentialExecutor/s/^/#/g&#x27; ~/airflow/airflow.cfg</span><br><span class="line">sed -i &#x27;/executor = SequentialExecutor/ a executor = LocalExecutor&#x27; ~/airflow/airflow.cfg</span><br><span class="line">airflow initdb</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">install awscli</span> </span><br><span class="line">pip install --upgrade --user awscli</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Download and unzip the Movielens dataset</span></span><br><span class="line">wget http://files.grouplens.org/datasets/movielens/ml-latest.zip &amp;&amp; unzip ml-latest.zip</span><br><span class="line"></span><br><span class="line">aws s3 cp ml-latest s3://kai-airflow-storage --recursive</span><br><span class="line"></span><br><span class="line">sudo pip install boto3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">for</span> all installation of py libraries, make sure to clear the conflicts by checking <span class="string">&quot;pip check&quot;</span></span></span><br><span class="line"></span><br><span class="line">apt install -y git</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Clone the git repository</span></span><br><span class="line">git clone https://github.com/aws-samples/aws-concurrent-data-orchestration-pipeline-emr-livy.git</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">Move all the files to the ~/airflow directory. The Airflow config file is setup to hold all the DAG related files <span class="keyword">in</span> the ~/airflow/ folder.</span></span><br><span class="line">mv aws-concurrent-data-orchestration-pipeline-emr-livy/* ~/airflow/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Delete the higher-level git repository directory</span></span><br><span class="line">rm -rf aws-concurrent-data-orchestration-pipeline-emr-livy</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Replace the name of the S3 bucket <span class="keyword">in</span> each of the .scala files. CHANGE THE HIGHLIGHTED PORTION BELOW TO THE NAME OF THE S3 BUCKET YOU CREATED IN STEP 1. The below <span class="built_in">command</span> replaces the instance of the string â€˜&lt;s3-bucket&gt;â€™ <span class="keyword">in</span> each of the scripts to the name of the actual bucket.</span></span><br><span class="line">sed -i &#x27;s/&lt;s3-bucket&gt;/kai-airflow-storage/g&#x27; /root/airflow/dags/transform/*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run airflow scheduler to start the DAGs</span></span><br><span class="line">airflow scheduler</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Run Airflow webserver</span></span><br><span class="line">airflow webserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">set</span> user and password once airflow is up and running</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">airflow <span class="built_in">users</span> create \</span></span><br><span class="line"><span class="language-bash"><span class="comment">#    --username admin \</span></span></span><br><span class="line"><span class="language-bash"><span class="comment">#    --firstname FIRST_NAME \</span></span></span><br><span class="line"><span class="language-bash"><span class="comment">#    --lastname LAST_NAME \</span></span></span><br><span class="line"><span class="language-bash"><span class="comment">#    --role Admin \</span></span></span><br><span class="line"><span class="language-bash"><span class="comment">#    --email admin@example.com</span></span></span><br><span class="line">airflow users create \</span><br><span class="line">    --username kaiadmin \</span><br><span class="line">    --firstname Kai \</span><br><span class="line">    --lastname Li \</span><br><span class="line">    --role Admin \</span><br><span class="line">    --email your_email@example.com</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">restart airflow services</span> </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">kill</span> all airflow processes</span> </span><br><span class="line">ps aux | grep &#x27;scheduler&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs -r sudo kill -9</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">kill</span> all worker</span> </span><br><span class="line">lsof -i :8793 | awk &#x27;NR&gt;1 &#123;print $2&#125;&#x27; | xargs sudo kill -9</span><br></pre></td></tr></table></figure>

<p>Note that the above setup is for testing purpose only. In production, you would want to consider deploying the worker services in other EC2 instances for setting a distributive Airflow service. Also, you would want to experiment containerized Airflow services management to avoid the hassle of Python library installation conflicts. </p>
<h2 id="2-Airflow-DAG-for-Lambda-Function-Creation"><a href="#2-Airflow-DAG-for-Lambda-Function-Creation" class="headerlink" title="2. Airflow DAG for Lambda Function Creation"></a>2. Airflow DAG for Lambda Function Creation</h2><p>Next, we define an Airflow DAG (<code>transform_movielens_v2</code>) to set up a Python script for cataloging Parquet files and creating a Lambda function.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> airflowlib.emr_lib <span class="keyword">as</span> emr</span><br><span class="line"><span class="keyword">import</span> os, boto3, logging, zipfile, textwrap</span><br><span class="line"><span class="keyword">from</span> airflow.models <span class="keyword">import</span> Variable</span><br><span class="line"><span class="meta">... </span>[rest of the imports] ...</span><br><span class="line"></span><br><span class="line">default_args = &#123;</span><br><span class="line">    ... [default args here] ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dag = DAG(<span class="string">&#x27;transform_movielens_v2&#x27;</span>, concurrency=<span class="number">3</span>, schedule_interval=<span class="literal">None</span>, default_args=default_args)</span><br><span class="line"></span><br><span class="line"><span class="meta">... </span>[rest of the DAG definition] ...</span><br><span class="line"></span><br><span class="line">create_zip_operator &gt;&gt; create_lambda_function_operator</span><br></pre></td></tr></table></figure>

<p>The full <code>movielens_dag_v2.py</code> script can be found at <a class="link"   target="_blank" rel="noopener" href="https://github.com/KaiLiPlayground/MovieLens_ETL_Proj/blob/main/movie_etl_proj/airflow/dags/movielens_dag_v2.py" >movielens_dag_v2.py<i class="fas fa-external-link-alt"></i></a></p>
<p>When both tasks ran in success, you should see the following</p>
<p><img src="/2024/01/31/MovieLensProj/lambda_function_creation_dag_tasks.png"></p>
<h2 id="3-Airflow-DAG-for-CSV-to-Parquet-Conversion"><a href="#3-Airflow-DAG-for-CSV-to-Parquet-Conversion" class="headerlink" title="3. Airflow DAG for CSV to Parquet Conversion"></a>3. Airflow DAG for CSV to Parquet Conversion</h2><p>We then define the main pipeline (<code>transform_movielens_v1</code>) for the CSV to Parquet conversion using EMR.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> airflowlib.emr_lib <span class="keyword">as</span> emr</span><br><span class="line"><span class="meta">... </span>[rest of the imports] ...</span><br><span class="line"></span><br><span class="line">default_args = &#123;</span><br><span class="line">    ... [default args here] ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dag = DAG(<span class="string">&#x27;transform_movielens_v1&#x27;</span>, concurrency=<span class="number">3</span>, schedule_interval=<span class="literal">None</span>, default_args=default_args)</span><br><span class="line"></span><br><span class="line"><span class="meta">... </span>[rest of the DAG definition] ...</span><br><span class="line"></span><br><span class="line">create_cluster &gt;&gt; wait_for_cluster_completion</span><br><span class="line"><span class="meta">... </span>[rest of the DAG dependencies] ...</span><br></pre></td></tr></table></figure>

<p>The full <code>transform_movielens_v1</code> dag can be found at <a class="link"   target="_blank" rel="noopener" href="https://github.com/KaiLiPlayground/MovieLens_ETL_Proj/blob/main/movie_etl_proj/airflow/dags/movielens_dag.py" >movielens_dag.py<i class="fas fa-external-link-alt"></i></a></p>
<p>When all tasks ran in success, we should see something as such: </p>
<p><img src="/2024/01/31/MovieLensProj/movie_dag_tasks.png"></p>
<h2 id="4-Extending-the-Pipeline-to-Load-Data-into-Redshift"><a href="#4-Extending-the-Pipeline-to-Load-Data-into-Redshift" class="headerlink" title="4. Extending the Pipeline to Load Data into Redshift"></a>4. Extending the Pipeline to Load Data into Redshift</h2><p>For further data modeling operations, we extend the pipeline to load the converted Parquet files into Redshift.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create_lambda_zip &gt;&gt; create_lambda_function &gt;&gt; create_cluster &gt;&gt; wait_for_cluster_completion</span><br><span class="line">wait_for_cluster_completion &gt;&gt; transform_movies &gt;&gt; load_to_redshift_movies &gt;&gt; terminate_cluster</span><br><span class="line"><span class="meta">... </span>[rest of the workflow] ...</span><br></pre></td></tr></table></figure>

<p>The Scala code for loading data into Redshift looks like this:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataframe = spark.read.parquet(<span class="string">&quot;s3://kai-airflow-storage/movielens-parquet/&lt;item&gt;&quot;</span>)</span><br><span class="line">dataframe.write</span><br><span class="line">  .format(<span class="string">&quot;io.github.spark_redshift_community.spark.redshift&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:redshift://&lt;redshift-url&gt;:5439/&lt;database&gt;?user=&lt;username&gt;&amp;password=&lt;password&gt;&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;&lt;table-name&gt;&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;tempdir&quot;</span>, <span class="string">&quot;s3://&lt;temp-bucket&gt;/temp&quot;</span>)</span><br><span class="line">  .mode(<span class="string">&quot;overwrite&quot;</span>)</span><br><span class="line">  .save()</span><br></pre></td></tr></table></figure>

<p><em>Note: EMR already contains the Redshift connector.</em></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This setup automates the process of transforming movie dataset files from CSV to Parquet and then loading them into Redshift for scalable data warehousing and modeling. It demonstrates the power and flexibility of AWS services and Apache Airflow in creating efficient data pipelines.</p>
<h2 id="Disclaimer"><a href="#Disclaimer" class="headerlink" title="Disclaimer"></a>Disclaimer</h2><p>The following post includes code snippets containing database passwords and AWS instance information. Please note that these are merely examples for demonstration purposes in a proof of concept context. We strongly advise you to modify these details in your implementation to prevent unintended expenses, particularly when utilizing high-cost resource SKUs in your cloud formation. It is imperative to carefully plan your resource usage ahead of time. Utilization of the code provided in this blog post is at your own discretion and responsibility.</p>

            </div>

            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/AWS-Lambda/">#AWS Lambda</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/AWS-EMR/">#AWS EMR</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/AWS-Airflow/">#AWS Airflow</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2023/12/28/DatabricksCertification/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Databricks Certification</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Building-an-Automated-Data-Pipeline-with-AWS-Airflow-and-Redshift"><span class="nav-number">1.</span> <span class="nav-text">Building an Automated Data Pipeline with AWS, Airflow, and Redshift</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-AWS-CloudFormation-Template-for-Infrastructure-Setup"><span class="nav-number">1.1.</span> <span class="nav-text">1. AWS CloudFormation Template for Infrastructure Setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Airflow-service-setup"><span class="nav-number">1.2.</span> <span class="nav-text">Airflow service setup</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Airflow-DAG-for-Lambda-Function-Creation"><span class="nav-number">1.3.</span> <span class="nav-text">2. Airflow DAG for Lambda Function Creation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Airflow-DAG-for-CSV-to-Parquet-Conversion"><span class="nav-number">1.4.</span> <span class="nav-text">3. Airflow DAG for CSV to Parquet Conversion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Extending-the-Pipeline-to-Load-Data-into-Redshift"><span class="nav-number">1.5.</span> <span class="nav-text">4. Extending the Pipeline to Load Data into Redshift</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-number">1.6.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Disclaimer"><span class="nav-number">1.7.</span> <span class="nav-text">Disclaimer</span></a></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2020</span> -
            
            2024
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Kai Li</a>
            
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block.js"></script>





<div class="post-scripts">
    
        
<script src="/js/post-helper.js"></script>

        
            
<script src="/js/libs/anime.min.js"></script>

        
        
            
<script src="/js/toc.js"></script>

        
    
</div>



</body>
</html>
